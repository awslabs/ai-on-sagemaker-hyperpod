"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[2740],{7764:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>l,frontMatter:()=>s,metadata:()=>t,toc:()=>u});const t=JSON.parse('{"id":"EKS Blueprints/Fine Tuning/Preference Alignment/Direct Preference Optimization","title":"Direct Preference Optimization","description":"","source":"@site/docs/1. EKS Blueprints/Fine Tuning/Preference Alignment/Direct Preference Optimization.md","sourceDirName":"1. EKS Blueprints/Fine Tuning/Preference Alignment","slug":"/EKS Blueprints/Fine Tuning/Preference Alignment/Direct Preference Optimization","permalink":"/ai-on-sagemaker-hyperpod/docs/EKS Blueprints/Fine Tuning/Preference Alignment/Direct Preference Optimization","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Quantisized LoRA","permalink":"/ai-on-sagemaker-hyperpod/docs/EKS Blueprints/Fine Tuning/PEFT/Quantisized LoRA/"},"next":{"title":"Proximal Policy Optimization","permalink":"/ai-on-sagemaker-hyperpod/docs/EKS Blueprints/Fine Tuning/Preference Alignment/Proximal Policy Optimization"}}');var r=i(4848),o=i(8453);const s={sidebar_position:1},a=void 0,c={},u=[];function p(e){return(0,r.jsx)(r.Fragment,{})}function l(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p()}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>a});var t=i(6540);const r={},o=t.createContext(r);function s(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);