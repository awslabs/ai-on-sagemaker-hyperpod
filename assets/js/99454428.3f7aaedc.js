"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3010],{8012:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"slurm-blueprints/training/ddp/distributed-data-parallel","title":"PyTorch DDP on CPU","description":"This example showcases CPU PyTorch DDP environment setup utilizing two different approaches for managing the software environment, Anaconda and Docker:","source":"@site/docs/02-slurm-blueprints/training/ddp/distributed-data-parallel.md","sourceDirName":"02-slurm-blueprints/training/ddp","slug":"/slurm-blueprints/training/ddp/distributed-data-parallel","permalink":"/ai-on-sagemaker-hyperpod/docs/slurm-blueprints/training/ddp/distributed-data-parallel","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"tile":"PyTorch DDP on CPU","sidebar_position":1,"sidebar_title":"PyTorch DDP on CPU"},"sidebar":"tutorialSidebar","previous":{"title":"Training","permalink":"/ai-on-sagemaker-hyperpod/docs/category/training-1"},"next":{"title":"Fully Sharded Data Parallel","permalink":"/ai-on-sagemaker-hyperpod/docs/slurm-blueprints/training/fsdp/fully-sharded-data-parallel"}}');var r=t(4848),s=t(8453);const o={tile:"PyTorch DDP on CPU",sidebar_position:1,sidebar_title:"PyTorch DDP on CPU"},a="PyTorch DDP on CPU",c={},d=[{value:"Preparation",id:"preparation",level:2},{value:"Conda Environment",id:"conda-environment",level:2},{value:"Submit training job using conda environment",id:"submit-training-job-using-conda-environment",level:3},{value:"Docker",id:"docker",level:2},{value:"Submit training job using docker container",id:"submit-training-job-using-docker-container",level:3},{value:"Monitor",id:"monitor",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"pytorch-ddp-on-cpu",children:"PyTorch DDP on CPU"})}),"\n",(0,r.jsxs)(n.p,{children:["This example showcases CPU ",(0,r.jsx)(n.a,{href:"https://pytorch.org/tutorials/beginner/ddp_series_theory.html",children:"PyTorch DDP"})," environment setup utilizing two different approaches for managing the software environment, Anaconda and Docker:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.anaconda.com/",children:"Anaconda"})," leverages conda environments to create distinct spaces for projects, allowing different Python versions and libraries to coexist without conflicts by isolating updates to their respective environments."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.docker.com/",children:"Docker"}),", a containerization platform, packages applications and their dependencies into containers, ensuring they run seamlessly across any Linux server by providing OS-level virtualization and encapsulating the entire runtime environment."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"preparation",children:"Preparation"}),"\n",(0,r.jsx)(n.p,{children:"This guide assumes that you have the following:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"A HyperPod Slurm cluster"}),"\n",(0,r.jsxs)(n.li,{children:["An FSx for Lustre filesystem mounted on ",(0,r.jsx)(n.code,{children:"/fsx"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["(optional) ",(0,r.jsx)(n.code,{children:"enroot"})," if you want to run the container example."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["If you don't already have a Slurm cluster, please follow the instructions in ",(0,r.jsx)(n.a,{href:"/docs/getting-started/orchestrated-by-slurm/initial-cluster-setup",children:(0,r.jsx)(n.strong,{children:"Cluster Setup"})})," to create one, then do the following:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"First clone the repo in a shared directory such as the home directory:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/aws-samples/awsome-distributed-training.git\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsx)(n.li,{children:"Change into the correct directory:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd awsome-distributed-training/3.test_cases/pytorch/cpu-ddp/slurm\n"})}),"\n",(0,r.jsx)(n.h2,{id:"conda-environment",children:"Conda Environment"}),"\n",(0,r.jsx)(n.h3,{id:"submit-training-job-using-conda-environment",children:"Submit training job using conda environment"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["In this step, you will create PyTorch virtual environment using conda, this will prepare ",(0,r.jsx)(n.code,{children:"miniconda3"})," and ",(0,r.jsx)(n.code,{children:"pt_cpu"})," directory which includes ",(0,r.jsx)(n.code,{children:"torchrun"}),":"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"bash 0.create-conda-env.sh\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsx)(n.li,{children:"Submit DDP training job with:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sbatch 1.conda-train.sbatch\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Output of the training job can be found in ",(0,r.jsx)(n.code,{children:"logs"})," directory:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"tail -f logs/cpu-ddp-conda_xxx.out\n"})}),"\n",(0,r.jsx)(n.p,{children:"You'll see:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Node IP: 10.1.96.108\n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] \n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] *****************************************\n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] *****************************************\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO] Starting elastic_operator with launch configs:\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   entrypoint       : ddp.py\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   min_nodes        : 2\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   max_nodes        : 2\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   nproc_per_node   : 4\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   run_id           : 5982\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   rdzv_backend     : c10d\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   rdzv_endpoint    : 10.1.96.108:29500\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   rdzv_configs     : {'timeout': 900}\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   max_restarts     : 0\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   monitor_interval : 5\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   log_dir          : None\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   metrics_cfg      : {}\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO] \n[2024-03-12 08:22:45,552] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] log directory set to: /tmp/torchelastic_9g50nxjq/5982_tflt1tcd\n[2024-03-12 08:22:45,552] torch.distributed.elastic.agent.server.api: [INFO] [default] starting workers for entrypoint: python\n...\n[RANK 3] Epoch 49 | Batchsize: 32 | Steps: 8\n[RANK 5] Epoch 49 | Batchsize: 32 | Steps: 8\n[RANK 4] Epoch 49 | Batchsize: 32 | Steps: 8\n[2024-03-12 08:22:56,574] torch.distributed.elastic.agent.server.api: [INFO] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n[2024-03-12 08:22:56,574] torch.distributed.elastic.agent.server.api: [INFO] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n[2024-03-12 08:22:56,575] torch.distributed.elastic.agent.server.api: [INFO] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n[2024-03-12 08:22:56,575] torch.distributed.elastic.agent.server.api: [INFO] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n[2024-03-12 08:22:56,575] torch.distributed.elastic.agent.server.api: [INFO] Done waiting for other agents. Elapsed: 0.0010929107666015625 seconds\n[2024-03-12 08:22:56,575] torch.distributed.elastic.agent.server.api: [INFO] Done waiting for other agents. Elapsed: 0.0005395412445068359 seconds\n"})}),"\n",(0,r.jsx)(n.h2,{id:"docker",children:"Docker"}),"\n",(0,r.jsx)(n.h3,{id:"submit-training-job-using-docker-container",children:"Submit training job using docker container"}),"\n",(0,r.jsx)(n.p,{children:"In this example, you'll learn how to use the official PyTorch Docker image and execute the container within the Slurm scheduler using Enroot."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://github.com/NVIDIA/enroot",children:"Enroot"})," uses the same underlying technologies as containers but removes much of the isolation they inherently provide while preserving filesystem separation. This approach is generally preferred in high-performance environments or virtualized environments where portability and reproducibility is important, but extra isolation is not warranted."]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Create Enroot container images:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"bash 2.create-enroot-image.sh\n"})}),"\n",(0,r.jsxs)(n.p,{children:["This will pull ",(0,r.jsx)(n.code,{children:"pytorch/pytorch"})," container, then create ",(0,r.jsx)(n.a,{href:"https://www.kernel.org/doc/Documentation/filesystems/squashfs.txt",children:"squashfs"})," image named ",(0,r.jsx)(n.code,{children:"pytorch.sqsh"}),"."]}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsx)(n.li,{children:"Submit DDP training job using the image with:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sbatch 3.container-train.sbatch\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"3",children:["\n",(0,r.jsxs)(n.li,{children:["Output of the training job can be found in ",(0,r.jsx)(n.code,{children:"logs"})," directory:"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"tail -f logs/cpu-ddp-container_*.out\n"})}),"\n",(0,r.jsx)(n.p,{children:"You'll see:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Node IP: 10.1.96.108\n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] \n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] *****************************************\n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n[2024-03-12 08:22:45,549] torch.distributed.run: [WARNING] *****************************************\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO] Starting elastic_operator with launch configs:\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   entrypoint       : ddp.py\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   min_nodes        : 2\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   max_nodes        : 2\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   nproc_per_node   : 4\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   run_id           : 5982\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   rdzv_backend     : c10d\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   rdzv_endpoint    : 10.1.96.108:29500\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   rdzv_configs     : {'timeout': 900}\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   max_restarts     : 0\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   monitor_interval : 5\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   log_dir          : None\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO]   metrics_cfg      : {}\n[2024-03-12 08:22:45,549] torch.distributed.launcher.api: [INFO] \n[2024-03-12 08:22:45,552] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] log directory set to: /tmp/torchelastic_9g50nxjq/5982_tflt1tcd\n[2024-03-12 08:22:45,552] torch.distributed.elastic.agent.server.api: [INFO] [default] starting workers for entrypoint: python\n...\n[RANK 3] Epoch 49 | Batchsize: 32 | Steps: 8\n[RANK 5] Epoch 49 | Batchsize: 32 | Steps: 8\n[RANK 4] Epoch 49 | Batchsize: 32 | Steps: 8\n[2024-03-12 08:22:56,574] torch.distributed.elastic.agent.server.api: [INFO] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n[2024-03-12 08:22:56,574] torch.distributed.elastic.agent.server.api: [INFO] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n[2024-03-12 08:22:56,575] torch.distributed.elastic.agent.server.api: [INFO] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n[2024-03-12 08:22:56,575] torch.distributed.elastic.agent.server.api: [INFO] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n[2024-03-12 08:22:56,575] torch.distributed.elastic.agent.server.api: [INFO] Done waiting for other agents. Elapsed: 0.0010929107666015625 seconds\n[2024-03-12 08:22:56,575] torch.distributed.elastic.agent.server.api: [INFO] Done waiting for other agents. Elapsed: 0.0005395412445068359 seconds\n"})}),"\n",(0,r.jsx)(n.h2,{id:"monitor",children:"Monitor"}),"\n",(0,r.jsx)(n.p,{children:"Now that the job is running, we can monitor it in two ways, we can tail the log file to see how the training is progressing:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Control-C to stop tailing\ntail -f slurm-2.log\n"})}),"\n",(0,r.jsx)(n.p,{children:"We can also ensure it's utilizing the CPU's appropriately by SSH-ing into the compute node."}),"\n",(0,r.jsxs)(n.p,{children:["Grab the hostname by running ",(0,r.jsx)(n.code,{children:"sinfo"})," and seeing which node it's running on:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sinfo\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\ndev*         up   infinite      1  alloc ip-10-1-90-87\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Then ssh into that instance using the hostname from ",(0,r.jsx)(n.code,{children:"sinfo"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ssh ip-10-1-90-87\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Once there we can monitor the cpu usage by running ",(0,r.jsx)(n.code,{children:"htop"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sudo apt-get install -y htop && htop\n"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(6540);const r={},s=i.createContext(r);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);