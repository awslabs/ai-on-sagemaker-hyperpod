"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3743],{4676:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>s,default:()=>h,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"eks-blueprints/inference/load-balancer-inference/inference-with-loadbalancer","title":"Mistral 7B Inference with Load Balancer","description":"This guide demonstrates how to deploy Mistral 7B for inference using Hugging Face\'s Text Generation Inference (TGI) container and expose it through an AWS Load Balancer on SageMaker HyperPod EKS.","source":"@site/docs/01-eks-blueprints/inference/load-balancer-inference/inference-with-loadbalancer.md","sourceDirName":"01-eks-blueprints/inference/load-balancer-inference","slug":"/eks-blueprints/inference/load-balancer-inference/inference-with-loadbalancer","permalink":"/docs/eks-blueprints/inference/load-balancer-inference/inference-with-loadbalancer","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Mistral 7B Inference with Load Balancer","sidebar_position":1,"sidebar_label":"Mistral 7B with Load Balancer"},"sidebar":"tutorialSidebar","previous":{"title":"Deploying model from S3 or FSX","permalink":"/docs/eks-blueprints/inference/inference-operator/amazon-s3-and-amazon-fsx"},"next":{"title":"SLURM Blueprints","permalink":"/docs/category/slurm-blueprints"}}');var t=r(4848),i=r(8453);const l={title:"Mistral 7B Inference with Load Balancer",sidebar_position:1,sidebar_label:"Mistral 7B with Load Balancer"},s="Mistral 7B Inference with TGI Container and Load Balancer",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"1. Setup Load Balancer Controller",id:"1-setup-load-balancer-controller",level:2},{value:"1.1 Set Environment Variables",id:"11-set-environment-variables",level:3},{value:"1.2 Associate IAM OIDC Provider",id:"12-associate-iam-oidc-provider",level:3},{value:"1.3 Create IAM Policy",id:"13-create-iam-policy",level:3},{value:"1.4 Create IAM Service Account",id:"14-create-iam-service-account",level:3},{value:"1.5 Install Load Balancer Controller",id:"15-install-load-balancer-controller",level:3},{value:"1.6 Verify Installation",id:"16-verify-installation",level:3},{value:"1.7 Configure Public Subnets",id:"17-configure-public-subnets",level:3},{value:"2. Deploy Mistral 7B with TGI",id:"2-deploy-mistral-7b-with-tgi",level:2},{value:"2.1 Create Deployment Manifest",id:"21-create-deployment-manifest",level:3},{value:"2.2 Configure Hugging Face Token",id:"22-configure-hugging-face-token",level:3},{value:"2.3 Deploy the Resources",id:"23-deploy-the-resources",level:3},{value:"2.4 Verify Deployment",id:"24-verify-deployment",level:3},{value:"3. Test the Inference Endpoint",id:"3-test-the-inference-endpoint",level:2},{value:"3.1 Get Load Balancer URL",id:"31-get-load-balancer-url",level:3},{value:"3.2 Expected Response",id:"32-expected-response",level:3},{value:"4. Cleanup",id:"4-cleanup",level:2},{value:"4.1 Delete the Deployment",id:"41-delete-the-deployment",level:3},{value:"4.2 Verify Cleanup",id:"42-verify-cleanup",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"Monitoring Commands",id:"monitoring-commands",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"mistral-7b-inference-with-tgi-container-and-load-balancer",children:"Mistral 7B Inference with TGI Container and Load Balancer"})}),"\n",(0,t.jsx)(n.p,{children:"This guide demonstrates how to deploy Mistral 7B for inference using Hugging Face's Text Generation Inference (TGI) container and expose it through an AWS Load Balancer on SageMaker HyperPod EKS."}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"The AWS Load Balancer Controller manages AWS Elastic Load Balancers for a Kubernetes cluster. You can use the controller to expose your models to the internet or internal traffic. The controller provisions AWS load balancers that point to cluster Service or Ingress resources deployed in your HyperPod cluster."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Model Requirements:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Mistral 7B"})," in fp16 requires 14 GB of GPU memory"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Instance requirement"}),": 1 A10G GPU minimum"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Container"}),": Hugging Face TGI container"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsx)(n.p,{children:"Before proceeding, ensure you have:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"A functional HyperPod EKS cluster with GPU nodes"}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"eksctl"})," installed for IAM OIDC provider creation"]}),"\n",(0,t.jsx)(n.li,{children:"A Hugging Face Hub token for model access"}),"\n",(0,t.jsx)(n.li,{children:"Appropriate AWS permissions for load balancer management"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"1-setup-load-balancer-controller",children:"1. Setup Load Balancer Controller"}),"\n",(0,t.jsx)(n.h3,{id:"11-set-environment-variables",children:"1.1 Set Environment Variables"}),"\n",(0,t.jsx)(n.p,{children:"Configure the required environment variables for your cluster:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"export AWS_REGION={your-region}\nexport EKS_CLUSTER_NAME={your-eks-cluster-name}\nexport HP_CLUSTER_NAME={your-hyperpod-cluster-name}\nexport VPC_ID={your-vpc-id}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"12-associate-iam-oidc-provider",children:"1.2 Associate IAM OIDC Provider"}),"\n",(0,t.jsx)(n.p,{children:"Associate your EKS cluster with IAM as an OIDC provider:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"eksctl utils associate-iam-oidc-provider \\\n    --region ${AWS_REGION} \\\n    --cluster ${EKS_CLUSTER_NAME} \\\n    --approve\n"})}),"\n",(0,t.jsx)(n.p,{children:"Expected output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'2024-06-21 11:23:06 [\u2139] eksctl version 0.69.0\n2024-06-21 11:23:06 [\u2139] using region us-east-1\n2024-06-21 11:23:07 [\u2139] will create IAM Open ID Connect provider for cluster "compass-beta" in "us-east-1"\n2024-06-21 11:23:08 [\u2714] created IAM Open ID Connect provider for cluster "compass-beta" in "us-east-1"\n'})}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsx)(n.p,{children:"If you receive a message that the IAM Open ID Connect provider is already associated with the cluster, proceed to the next step."})}),"\n",(0,t.jsx)(n.h3,{id:"13-create-iam-policy",children:"1.3 Create IAM Policy"}),"\n",(0,t.jsx)(n.p,{children:"Create an IAM policy for the AWS Load Balancer Controller:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"curl -o iam-policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.10.0/docs/install/iam_policy.json\n\naws iam create-policy \\\n      --policy-name AWSLoadBalancerControllerIAMPolicy \\\n      --policy-document file://iam-policy.json\n"})}),"\n",(0,t.jsx)(n.h3,{id:"14-create-iam-service-account",children:"1.4 Create IAM Service Account"}),"\n",(0,t.jsx)(n.p,{children:"Create an IAM role and associate it with the service account:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'ACCOUNT_ID=$(aws sts get-caller-identity --query "Account" --output text)\n\neksctl create iamserviceaccount \\\n--cluster=${EKS_CLUSTER_NAME} \\\n--namespace=kube-system \\\n--name=aws-load-balancer-controller \\\n--attach-policy-arn=arn:aws:iam::${ACCOUNT_ID}:policy/AWSLoadBalancerControllerIAMPolicy \\\n--override-existing-serviceaccounts \\\n--region=${AWS_REGION} \\\n--approve\n'})}),"\n",(0,t.jsx)(n.h3,{id:"15-install-load-balancer-controller",children:"1.5 Install Load Balancer Controller"}),"\n",(0,t.jsx)(n.p,{children:"Install the AWS Load Balancer Controller using Helm:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Add EKS Helm charts\nhelm repo add eks https://aws.github.io/eks-charts\nhelm repo update eks\n\n# Install the controller\nhelm install aws-load-balancer-controller eks/aws-load-balancer-controller \\\n  -n kube-system \\\n  --set clusterName=${HP_CLUSTER_NAME} \\\n  --set serviceAccount.create=false \\\n  --set serviceAccount.name=aws-load-balancer-controller \\\n  --set vpcId=${VPC_ID} \\\n  --set region=${AWS_REGION}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"16-verify-installation",children:"1.6 Verify Installation"}),"\n",(0,t.jsx)(n.p,{children:"Verify that version v2.10.0 or later is installed (required for HyperPod support):"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"helm ls -n kube-system\n"})}),"\n",(0,t.jsx)(n.p,{children:"Expected output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"NAME                        \tNAMESPACE  \tREVISION\tUPDATED                             \tSTATUS  \tCHART                              \tAPP VERSION\naws-load-balancer-controller\tkube-system\t1       \t2024-11-03 00:10:46.548465 -0700 PDT\tdeployed\taws-load-balancer-controller-1.10.0\tv2.10.0    \n"})}),"\n",(0,t.jsx)(n.p,{children:"Check that the controller pods are running:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kubectl get pods -n kube-system | grep aws-load-balancer-controller\n"})}),"\n",(0,t.jsx)(n.h3,{id:"17-configure-public-subnets",children:"1.7 Configure Public Subnets"}),"\n",(0,t.jsx)(n.p,{children:"Tag the public subnets for load balancer usage:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Get public subnets\nPUBLIC_SUBNETS=$(aws ec2 describe-subnets --filters "[ {\\"Name\\":\\"vpc-id\\",\\"Values\\":[\\"${VPC_ID}\\"]}, {\\"Name\\":\\"map-public-ip-on-launch\\",\\"Values\\":[\\"true\\"]} ]" --query \'Subnets[*].{SubnetId:SubnetId}\' --output text)\n\n# Add required tags\nfor SUBNET_ID in $PUBLIC_SUBNETS; do\n    aws ec2 create-tags --resources $SUBNET_ID --tags Key=kubernetes.io/role/elb,Value=1\ndone\n'})}),"\n",(0,t.jsx)(n.p,{children:"Verify the tags were added:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'for SUBNET_ID in $PUBLIC_SUBNETS; do\n    aws ec2 describe-tags --filters "Name=resource-id,Values=${SUBNET_ID}"\ndone\n'})}),"\n",(0,t.jsx)(n.h2,{id:"2-deploy-mistral-7b-with-tgi",children:"2. Deploy Mistral 7B with TGI"}),"\n",(0,t.jsx)(n.h3,{id:"21-create-deployment-manifest",children:"2.1 Create Deployment Manifest"}),"\n",(0,t.jsx)(n.p,{children:"Create the Kubernetes manifest for Mistral 7B deployment:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'cat <<EOF > mistral_TGI_eks.yml\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: text-inference\n  labels:\n    app: text-inference\nspec:\n  containers:\n    - name: text-generation-inference\n      image: ghcr.io/huggingface/text-generation-inference:2.1.1\n      resources:\n        limits:\n          nvidia.com/gpu: 1\n        requests:\n          cpu: "4"\n          memory: 4Gi\n          nvidia.com/gpu: 1\n      command:\n        - "text-generation-launcher"\n        - "--model-id"\n        - "mistralai/Mistral-7B-Instruct-v0.2"\n        - "--num-shard"\n        - "1"\n      ports:\n        - containerPort: 80\n          name: http\n      volumeMounts:\n        - name: model\n          mountPath: /data\n        - name: shm\n          mountPath: /dev/shm\n      env:\n        - name: HUGGING_FACE_HUB_TOKEN\n          value: "YOUR_HF_TOKEN_HERE"  # Replace with your actual token\n  volumes:\n    - name: model\n      hostPath:\n       path: /opt/dlami/nvme\n       type: DirectoryOrCreate\n    - name: shm\n      emptyDir:\n        medium: Memory\n        sizeLimit: 1Gi\n  tolerations:\n    - key: "nvidia.com/gpu"\n      operator: "Exists"\n      effect: "NoSchedule"\n  restartPolicy: Never\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: text-inference-nlb\n  annotations:\n    # NLB specific annotations\n    service.beta.kubernetes.io/aws-load-balancer-type: "external"\n    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"\n    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"\nspec:\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: http\n  selector:\n    app: text-inference\n  type: LoadBalancer\nEOF\n'})}),"\n",(0,t.jsx)(n.h3,{id:"22-configure-hugging-face-token",children:"2.2 Configure Hugging Face Token"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Important"}),": Update the ",(0,t.jsx)(n.code,{children:"HUGGING_FACE_HUB_TOKEN"})," value in the manifest with your actual Hugging Face token before deploying."]}),"\n",(0,t.jsxs)(n.p,{children:["Edit the file and replace ",(0,t.jsx)(n.code,{children:"YOUR_HF_TOKEN_HERE"})," with your token:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Edit the file to add your Hugging Face token\nvim mistral_TGI_eks.yml\n"})}),"\n",(0,t.jsx)(n.h3,{id:"23-deploy-the-resources",children:"2.3 Deploy the Resources"}),"\n",(0,t.jsx)(n.p,{children:"Deploy the Mistral 7B inference service:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f mistral_TGI_eks.yml\n"})}),"\n",(0,t.jsx)(n.h3,{id:"24-verify-deployment",children:"2.4 Verify Deployment"}),"\n",(0,t.jsx)(n.p,{children:"Check that the pod is running:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kubectl get pods\n"})}),"\n",(0,t.jsx)(n.p,{children:"Expected output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"NAME             READY   STATUS      RESTARTS        AGE   IP              NODE                           NOMINATED NODE   READINESS GATES\ntext-inference   1/1     Running     0               26d   10.192.20.179   hyperpod-i-04c866398de1d6c9b   <none>           <none>\n"})}),"\n",(0,t.jsx)(n.p,{children:"Check the service and load balancer:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kubectl get svc\n"})}),"\n",(0,t.jsx)(n.p,{children:"Expected output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"text-inference-nlb   LoadBalancer   172.20.155.118   k8s-default-textinfe-6b45939327-004c0b23beebf81f.elb.us-east-1.amazonaws.com   80:31584/TCP   69m\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsx)(n.p,{children:"Wait for the load balancer to be fully provisioned. You can check the status in the AWS Console under EC2 \u2192 Load Balancers."})}),"\n",(0,t.jsx)(n.h2,{id:"3-test-the-inference-endpoint",children:"3. Test the Inference Endpoint"}),"\n",(0,t.jsx)(n.h3,{id:"31-get-load-balancer-url",children:"3.1 Get Load Balancer URL"}),"\n",(0,t.jsx)(n.p,{children:"Copy the DNS name from the service output above and test the inference endpoint:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Replace with your actual load balancer DNS name\nexport LB_URL="k8s-default-textinfe-6b45939327-004c0b23beebf81f.elb.us-east-1.amazonaws.com"\n\n# Test the inference endpoint\ncurl http://${LB_URL}:80/generate \\\n  -X POST \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "inputs": "how to make chocolate cake",\n    "parameters": {\n      "max_new_tokens": 256,\n      "temperature": 0.5\n    }\n  }\'\n'})}),"\n",(0,t.jsx)(n.h3,{id:"32-expected-response",children:"3.2 Expected Response"}),"\n",(0,t.jsx)(n.p,{children:"You should receive a response similar to:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "generated_text": " with sour cream?\\n\\nYou can make a chocolate cake with sour cream by adding sour cream to the batter. This will give the cake a richer flavor and make it more moist.\\n\\n## What is the best way to make a chocolate cake from scratch?\\n\\nThere are many different ways to make a chocolate cake from scratch, but there are a few key steps that are essential to making a delicious and moist cake. First, you will need to mix together the dry ingredients. This includes flour, sugar, cocoa powder, baking powder, and salt. Once the dry ingredients are combined, you will need to add in the wet ingredients. This includes eggs, milk, and vegetable oil. Finally, you will need to bake the cake in a preheated oven.\\n\\n## What are the key ingredients in a chocolate cake?\\n\\nThere are many different ways to make a chocolate cake, but there are a few key ingredients that are essential for a delicious and moist cake. The first key ingredient is chocolate. The type of chocolate you use will determine the flavor and richness of your cake. For a classic chocolate cake, you will need unsweetened chocolate. The second key ingredient is butter. Butter adds flavor and rich"\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"4-cleanup",children:"4. Cleanup"}),"\n",(0,t.jsx)(n.h3,{id:"41-delete-the-deployment",children:"4.1 Delete the Deployment"}),"\n",(0,t.jsx)(n.p,{children:"To remove the Mistral 7B deployment and associated resources:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kubectl delete -f mistral_TGI_eks.yml\n"})}),"\n",(0,t.jsx)(n.h3,{id:"42-verify-cleanup",children:"4.2 Verify Cleanup"}),"\n",(0,t.jsx)(n.p,{children:"Confirm that the resources have been deleted:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kubectl get pods\nkubectl get svc\n"})}),"\n",(0,t.jsx)(n.p,{children:"The load balancer will also be automatically deleted when the service is removed."}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Pod not starting"}),": Check if GPU resources are available and the Hugging Face token is valid"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Load balancer not accessible"}),": Verify that public subnets are properly tagged"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Model download issues"}),": Ensure the Hugging Face token has access to the Mistral model"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"monitoring-commands",children:"Monitoring Commands"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Check pod logs\nkubectl logs text-inference\n\n# Describe pod for events\nkubectl describe pod text-inference\n\n# Check service status\nkubectl describe svc text-inference-nlb\n"})}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scale the deployment"}),": Convert to a Deployment with multiple replicas for higher availability"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Add monitoring"}),": Integrate with Prometheus and Grafana for performance monitoring"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Implement autoscaling"}),": Use Horizontal Pod Autoscaler based on request metrics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Security enhancements"}),": Add authentication and rate limiting to the inference endpoint"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["For more advanced configurations and other model deployments, refer to the ",(0,t.jsx)(n.a,{href:"https://huggingface.co/docs/text-generation-inference/index",children:"Hugging Face TGI documentation"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>s});var a=r(6540);const t={},i=a.createContext(t);function l(e){const n=a.useContext(i);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);