"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[6768],{2681:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"eks-blueprints/training/ddp/distributed-data-parallel","title":"Data Distributed Parallelism (DDP)","description":"Setup your training job image","source":"@site/docs/01-eks-blueprints/training/ddp/distributed-data-parallel.md","sourceDirName":"01-eks-blueprints/training/ddp","slug":"/eks-blueprints/training/ddp/distributed-data-parallel","permalink":"/docs/eks-blueprints/training/ddp/distributed-data-parallel","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Data Distributed Parallelism (DDP)","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"WIP","permalink":"/docs/eks-blueprints/training/ray-train/"},"next":{"title":"Fully Sharded Data Parallelism (FSDP)","permalink":"/docs/eks-blueprints/training/fsdp/fully-sharded-data-parallel"}}');var i=s(4848),r=s(8453);const o={title:"Data Distributed Parallelism (DDP)",sidebar_position:1},a="Get Started Training a Model using PyTorch DDP in 5 Minutes",l={},c=[{value:"Setup your training job image",id:"setup-your-training-job-image",level:2},{value:"Build a docker image",id:"build-a-docker-image",level:3},{value:"Preparing your trainig job script",id:"preparing-your-trainig-job-script",level:2},{value:"Install envsubst",id:"install-envsubst",level:3},{value:"Generate manifest from template",id:"generate-manifest-from-template",level:3},{value:"Deploy training workload",id:"deploy-training-workload",level:3},{value:"Monitor",id:"monitor",level:3},{value:"Stop",id:"stop",level:3},{value:"Start your training job execution",id:"start-your-training-job-execution",level:2},{value:"Clone the repo",id:"clone-the-repo",level:3},{value:"Deploy training workload",id:"deploy-training-workload-1",level:3},{value:"Monitor",id:"monitor-1",level:3},{value:"Stop",id:"stop-1",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",div:"div",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"get-started-training-a-model-using-pytorch-ddp-in-5-minutes",children:"Get Started Training a Model using PyTorch DDP in 5 Minutes"})}),"\n",(0,i.jsx)(n.h2,{id:"setup-your-training-job-image",children:"Setup your training job image"}),"\n",(0,i.jsx)(n.h3,{id:"build-a-docker-image",children:"Build a docker image"}),"\n",(0,i.jsx)(n.p,{children:"On your x86-64 based development environment:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Navigate to your home directory or your preferred project directory, clone the repo."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd ~\ngit clone https://github.com/aws-samples/awsome-distributed-training/\ncd awsome-distributed-training/3.test_cases/pytorch/cpu-ddp/kubernetes\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Build the container image."}),"\n",(0,i.jsx)(n.p,{children:"Build a container image for this example using the code below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export AWS_REGION=$(aws ec2 describe-availability-zones --output text --query 'AvailabilityZones[0].[RegionName]')\nexport ACCOUNT=$(aws sts get-caller-identity --query Account --output text)\nexport REGISTRY=${ACCOUNT}.dkr.ecr.${AWS_REGION}.amazonaws.com/\ndocker build $DOCKER_NETWORK -t ${REGISTRY}fsdp:pytorch2.2-cpu ..\n"})}),"\n",(0,i.jsx)(n.div,{children:(0,i.jsx)(n.div,{children:(0,i.jsxs)(n.p,{children:["The environment variable",(0,i.jsx)(n.code,{children:"$DOCKER_NETWORK"})," is set to ",(0,i.jsx)(n.code,{children:"--network=sagemaker"})," only if you deployed the SageMaker Studio Code Editor CloudFormation stack in the ",(0,i.jsx)(n.a,{href:"/docs/category/getting-started",children:"Set Up Your Development Environment"})," section. This is necessary because SageMaker Studio uses a specific network configuration for its containers. Otherwise, it remains unset."]})})}),"\n",(0,i.jsx)(n.p,{children:"Building image can take 3~5min. If successful, you should see following success message at the end."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Successfully built 123ab12345cd\nSuccessfully tagged 123456789012.dkr.ecr.us-east-2.amazonaws.com/fsdp:pytorch2.2-cpu\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Push the image to Amazon ECR"}),"\n",(0,i.jsx)(n.p,{children:"In this step we create a container registry if one does not exist, and push the container image to it."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Create registry if needed\nREGISTRY_COUNT=$(aws ecr describe-repositories | grep \\"fsdp\\" | wc -l)\nif [ "$REGISTRY_COUNT" == "0" ]; then\n        aws ecr create-repository --repository-name fsdp\nfi\n\n# Login to registry\necho "Logging in to $REGISTRY ..."\naws ecr get-login-password | docker login --username AWS --password-stdin $REGISTRY\n\n# Push image to registry\ndocker image push ${REGISTRY}fsdp:pytorch2.2-cpu\n'})}),"\n",(0,i.jsx)(n.p,{children:"Pushing the image may take some time depending on your network bandwidth. If you use EC2 / CloudShell as your development machine, it will take 6~8 min."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"preparing-your-trainig-job-script",children:"Preparing your trainig job script"}),"\n",(0,i.jsx)(n.h3,{id:"install-envsubst",children:"Install envsubst"}),"\n",(0,i.jsxs)(n.p,{children:["This example uses ",(0,i.jsx)(n.a,{href:"https://github.com/a8m/envsubst",children:(0,i.jsx)(n.code,{children:"envsubst"})})," to generate a Kubernetes manifest file from a template file and parameters. If you don't have ",(0,i.jsx)(n.code,{children:"envsubst"})," on your development environment, install it by following the ",(0,i.jsx)(n.a,{href:"https://github.com/a8m/envsubst?tab=readme-ov-file#installation",children:"Installation instruction"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"generate-manifest-from-template",children:"Generate manifest from template"}),"\n",(0,i.jsxs)(n.p,{children:["With the ",(0,i.jsx)(n.code,{children:"envsubst"})," command, generate ",(0,i.jsx)(n.code,{children:"fsdp.yaml"})," from ",(0,i.jsx)(n.code,{children:"fsdp.yaml-template"}),". Please configure instance type, number of nodes, number of CPUs, based on your cluster's specification."]}),"\n",(0,i.jsx)(n.p,{children:"You can check your cluster's specification by running following command:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'kubectl get nodes "-o=custom-columns=NAME:.metadata.name,INSTANCETYPE:.metadata.labels.node\\.kubernetes\\.io/instance-type,CPU:.status.capacity.cpu"\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"NAME                           INSTANCETYPE    CPU\nhyperpod-i-0427a1830f8e4a49e   ml.m5.2xlarge   4\nhyperpod-i-052768f9f54856cd6   ml.m5.2xlarge   4\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Set environment variables and run ",(0,i.jsx)(n.code,{children:"envsubst"})," to generate ",(0,i.jsx)(n.code,{children:"fsdp.yaml"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"For ml.m5.2xlarge x 2:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export IMAGE_URI=${REGISTRY}fsdp:pytorch2.2-cpu\nexport INSTANCE_TYPE=ml.m5.2xlarge\nexport NUM_NODES=2\nexport CPU_PER_NODE=4\ncat fsdp.yaml-template | envsubst > fsdp.yaml\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The template file assumes that the FSx Lustre volume is claimed as ",(0,i.jsx)(n.code,{children:"fsx-pvc"}),". You can check the claim name of the FSx Lustre filesystem in your cluster by executing following command."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl get pvc\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE\nfsx-claim   Bound    pvc-ed0fd2cb-33da-498d-bab4-bf08cb4d555c   1200Gi     RWX            fsx-sc         <unset>                 6d22h\n"})}),"\n",(0,i.jsxs)(n.p,{children:["If your FSx Lustre volume is claimed in different name than ",(0,i.jsx)(n.code,{children:"fsx-pvc"})," (e.g., ",(0,i.jsx)(n.code,{children:"fsx-claim"}),"), you can execute the following command to update the claim name in ",(0,i.jsx)(n.code,{children:"fsdp.yaml"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sed 's/fsx-pv/fsx-claim/g' -i ./fsdp.yaml\n"})}),"\n",(0,i.jsxs)(n.p,{children:["If you wish the training job to run for longer so you may test resiliency against a running job,\nincrease the number of epochs by increasing the number of epochs specified by the torchrun command in ",(0,i.jsx)(n.code,{children:"fsdp.yaml"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sed 's/5000/50000/g' -i ./fsdp.yaml\n"})}),"\n",(0,i.jsxs)(n.p,{children:["In this example the number of epochs (line 107) was increased from ",(0,i.jsx)(n.code,{children:"5000"})," to ",(0,i.jsx)(n.code,{children:"50000"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"deploy-training-workload",children:"Deploy training workload"}),"\n",(0,i.jsxs)(n.p,{children:["Now the manifest file ",(0,i.jsx)(n.code,{children:"fsdp.yaml"})," is generated, and you are ready to deploy the training workload. Run following command to deploy the training workload."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f ./fsdp.yaml\n"})}),"\n",(0,i.jsx)(n.p,{children:"You should see following message."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"service/etcd created\ndeployment.apps/etcd created\npytorchjob.kubeflow.org/fsdp created\n"})}),"\n",(0,i.jsx)(n.h3,{id:"monitor",children:"Monitor"}),"\n",(0,i.jsx)(n.p,{children:"To see the status of your job, use the commands below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl get pytorchjob\nkubectl get pods\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"NAME   STATE     AGE\nfsdp   Running   40s\n\nNAME                    READY   STATUS    RESTARTS   AGE\netcd-7787559c74-msgpq   1/1     Running   0          49s\nfsdp-worker-0           1/1     Running   0          49s\nfsdp-worker-1           1/1     Running   0          49s\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["Note: When you run for the first time, it takes 2~3min until the Pod statuses change from ",(0,i.jsx)(n.code,{children:"ContainerCreating"})," to ",(0,i.jsx)(n.code,{children:"Running"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Each of the pods produces job logs. You can monitor the logs by running the command below."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl logs -f fsdp-worker-0\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"2024-07-19 04:39:07,890] torch.distributed.run: [WARNING] *****************************************\nINFO 2024-07-19 04:39:07,958 Etcd machines: ['http://0.0.0.0:2379']\nINFO 2024-07-19 04:39:07,964 Attempting to join next rendezvous\nINFO 2024-07-19 04:39:07,965 Observed existing rendezvous state: {'status': 'joinable', 'version': '1', 'participants': [0]}\nINFO 2024-07-19 04:39:08,062 Joined rendezvous version 1 as rank 1. Full state: {'status': 'frozen', 'version': '1', 'participants': [0, 1], 'keep_alives': []}\nINFO 2024-07-19 04:39:08,062 Waiting for remaining peers.\nINFO 2024-07-19 04:39:08,063 All peers arrived. Confirming membership.\nINFO 2024-07-19 04:39:08,149 Waiting for confirmations from all peers.\nINFO 2024-07-19 04:39:08,161 Rendezvous version 1 is complete. Final state: {'status': 'final', 'version': '1', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_none/rdzv/v_1/rank_1', '/torchelastic/p2p/run_none/rdzv/v_1/rank_0'], 'num_workers_waiting': 0}\nINFO 2024-07-19 04:39:08,161 Creating EtcdStore as the c10d::Store implementation\n...\n[RANK 1] Epoch 4991 | Batchsize: 32 | Steps: 8\nEpoch 4990 | Training snapshot saved at /fsx/snapshot.pt\n[RANK 0] Epoch 4991 | Batchsize: 32 | Steps: 8\n[RANK 1] Epoch 4992 | Batchsize: 32 | Steps: 8\n[RANK 0] Epoch 4992 | Batchsize: 32 | Steps: 8\n[RANK 3] Epoch 4992 | Batchsize: 32 | Steps: 8\n[RANK 2] Epoch 4992 | Batchsize: 32 | Steps: 8\n[RANK 1] Epoch 4993 | Batchsize: 32 | Steps: 8\n[RANK 2] Epoch 4993 | Batchsize: 32 | Steps: 8\n"})}),"\n",(0,i.jsx)(n.h3,{id:"stop",children:"Stop"}),"\n",(0,i.jsx)(n.p,{children:"To stop the current training job, use the following command."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl delete -f ./fsdp.yaml\n"})}),"\n",(0,i.jsx)(n.h2,{id:"start-your-training-job-execution",children:"Start your training job execution"}),"\n",(0,i.jsx)(n.h3,{id:"clone-the-repo",children:"Clone the repo"}),"\n",(0,i.jsx)(n.p,{children:"Navigate to your home directory or your preferred project directory, clone the repo."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd ~\ngit clone https://github.com/aws-samples/awsome-distributed-training/\ncd awsome-distributed-training/3.test_cases/pytorch/cpu-ddp/kubernetes\n"})}),"\n",(0,i.jsx)(n.p,{children:"If you wish to test the resiliency feature, please run the following command to increase the number of training epochs so the job runs longer:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sed 's/5000/50000/g' -i ./fsdp-simple.yaml\n"})}),"\n",(0,i.jsx)(n.h3,{id:"deploy-training-workload-1",children:"Deploy training workload"}),"\n",(0,i.jsx)(n.p,{children:"Run following command to deploy the training workload."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f ./fsdp-simple.yaml\n"})}),"\n",(0,i.jsx)(n.p,{children:"You should see following message."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"service/etcd created\ndeployment.apps/etcd created\npytorchjob.kubeflow.org/fsdp created\n"})}),"\n",(0,i.jsx)(n.h3,{id:"monitor-1",children:"Monitor"}),"\n",(0,i.jsx)(n.p,{children:"To see the status of your job, use the commands below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl get pytorchjob\nkubectl get pods\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"NAME   STATE     AGE\nfsdp   Running   40s\n\nNAME                    READY   STATUS    RESTARTS   AGE\netcd-7787559c74-msgpq   1/1     Running   0          49s\nfsdp-worker-0           1/1     Running   0          49s\nfsdp-worker-1           1/1     Running   0          49s\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["Note: When you run for the first time, it takes 2~3min until the Pod statuses change from ",(0,i.jsx)(n.code,{children:"ContainerCreating"})," to ",(0,i.jsx)(n.code,{children:"Running"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Each of the pods produces job logs. You can monitor the logs by running the command below."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl logs -f fsdp-worker-0\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"2024-07-19 04:39:07,890] torch.distributed.run: [WARNING] *****************************************\nINFO 2024-07-19 04:39:07,958 Etcd machines: ['http://0.0.0.0:2379']\nINFO 2024-07-19 04:39:07,964 Attempting to join next rendezvous\nINFO 2024-07-19 04:39:07,965 Observed existing rendezvous state: {'status': 'joinable', 'version': '1', 'participants': [0]}\nINFO 2024-07-19 04:39:08,062 Joined rendezvous version 1 as rank 1. Full state: {'status': 'frozen', 'version': '1', 'participants': [0, 1], 'keep_alives': []}\nINFO 2024-07-19 04:39:08,062 Waiting for remaining peers.\nINFO 2024-07-19 04:39:08,063 All peers arrived. Confirming membership.\nINFO 2024-07-19 04:39:08,149 Waiting for confirmations from all peers.\nINFO 2024-07-19 04:39:08,161 Rendezvous version 1 is complete. Final state: {'status': 'final', 'version': '1', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_none/rdzv/v_1/rank_1', '/torchelastic/p2p/run_none/rdzv/v_1/rank_0'], 'num_workers_waiting': 0}\nINFO 2024-07-19 04:39:08,161 Creating EtcdStore as the c10d::Store implementation\n...\n[RANK 1] Epoch 4991 | Batchsize: 32 | Steps: 8\nEpoch 4990 | Training snapshot saved at /fsx/snapshot.pt\n[RANK 0] Epoch 4991 | Batchsize: 32 | Steps: 8\n[RANK 1] Epoch 4992 | Batchsize: 32 | Steps: 8\n[RANK 0] Epoch 4992 | Batchsize: 32 | Steps: 8\n[RANK 3] Epoch 4992 | Batchsize: 32 | Steps: 8\n[RANK 2] Epoch 4992 | Batchsize: 32 | Steps: 8\n[RANK 1] Epoch 4993 | Batchsize: 32 | Steps: 8\n[RANK 2] Epoch 4993 | Batchsize: 32 | Steps: 8\n"})}),"\n",(0,i.jsx)(n.h3,{id:"stop-1",children:"Stop"}),"\n",(0,i.jsx)(n.p,{children:"To stop the current training job, use the following command."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl delete -f ./fsdp-simple.yaml\n"})})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>a});var t=s(6540);const i={},r=t.createContext(i);function o(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);