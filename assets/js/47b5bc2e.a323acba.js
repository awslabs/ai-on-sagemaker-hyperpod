"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[7653],{3183:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"add-ons/Scripts/NCCL and CUDA validation/Troubleshoot NCCL and CUDA","title":"Troubleshoot NCCL and CUDA","description":"There are moments where you are stuck either because things are not working or the performnace is not what you expected. Most, not always, it will be an issue with libraries and drivers. For GPU-based workloads, those issues can show up more frequently as there are many bits and pieces that need to be working together. A simple mismatch of a library version or not-optimized driver version for that specific librabry version can break things.","source":"@site/docs/04-add-ons/Scripts/NCCL and CUDA validation/Troubleshoot NCCL and CUDA.md","sourceDirName":"04-add-ons/Scripts/NCCL and CUDA validation","slug":"/add-ons/Scripts/NCCL and CUDA validation/Troubleshoot NCCL and CUDA","permalink":"/docs/add-ons/Scripts/NCCL and CUDA validation/Troubleshoot NCCL and CUDA","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Troubleshoot NCCL and CUDA","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Monitoring","permalink":"/docs/add-ons/Scripts/Monitoring/"},"next":{"title":"Performance Testing","permalink":"/docs/add-ons/Scripts/Performance Testing/"}}');var o=i(4848),r=i(8453);const s={title:"Troubleshoot NCCL and CUDA",sidebar_position:1},a="Troubleshooting NCCL and CUDA - a (not) comprehensive guide",c={},d=[{value:"CUDA - Compute Unified Device Architecture",id:"cuda---compute-unified-device-architecture",level:2},{value:"Background history and architecture overview",id:"background-history-and-architecture-overview",level:3},{value:"Debug and test if the CUDA environment is okay",id:"debug-and-test-if-the-cuda-environment-is-okay",level:2},{value:"Possible solutions",id:"possible-solutions",level:2},{value:"CUDA driver and NVCC (compiler) versions mismatch",id:"cuda-driver-and-nvcc-compiler-versions-mismatch",level:3},{value:"CUDA device not intialized",id:"cuda-device-not-intialized",level:3},{value:"NVLink status and topology",id:"nvlink-status-and-topology",level:3}];function l(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"troubleshooting-nccl-and-cuda---a-not-comprehensive-guide",children:"Troubleshooting NCCL and CUDA - a (not) comprehensive guide"})}),"\n",(0,o.jsx)(n.p,{children:"There are moments where you are stuck either because things are not working or the performnace is not what you expected. Most, not always, it will be an issue with libraries and drivers. For GPU-based workloads, those issues can show up more frequently as there are many bits and pieces that need to be working together. A simple mismatch of a library version or not-optimized driver version for that specific librabry version can break things."}),"\n",(0,o.jsx)(n.p,{children:"Let's start with creating simple scripts that will help us debug and validate our environment."}),"\n",(0,o.jsx)(n.h2,{id:"cuda---compute-unified-device-architecture",children:"CUDA - Compute Unified Device Architecture"}),"\n",(0,o.jsx)(n.h3,{id:"background-history-and-architecture-overview",children:"Background history and architecture overview"}),"\n",(0,o.jsx)(n.p,{children:"NVIDIA CUDA is the platform required to run workloads using your GPU. Initially designed for rendering graphics, hence the name Graphic Processing Unit (GPU), the GPU has become much more than that. Starting circa 2006, NVIDIA launched the CUDA platform and allowed their GPU to become GPGPU: General Purpose Graphic Processing Unit. This meant that now you could run workloads using your GPGPU instead of the CPU to execute binary code."}),"\n",(0,o.jsx)(n.p,{children:"In order to develop an application that uses your GPGPU (i'll start abbreviating as GPU from now on), you need a few things to work together:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"a GPU device. The latests ones, as of September 2025, are the H200, B200 (Blackwell) and the GB200 (Grace Hopper Blackwell)."}),"\n",(0,o.jsx)(n.li,{children:"a GPU driver."}),"\n",(0,o.jsx)(n.li,{children:"a CUDA runtime."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"debug-and-test-if-the-cuda-environment-is-okay",children:"Debug and test if the CUDA environment is okay"}),"\n",(0,o.jsx)(n.p,{children:"Here is a simple debug script that will output an error code which we can use later:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-c",children:'#include <cuda.h>\n#include <stdio.h>\n\nint main() {\n    CUresult result = cuInit(0);\n    printf("cuInit result: %d\\n", result);\n\n    if (result == CUDA_SUCCESS) {\n        int count;\n        cuDeviceGetCount(&count);\n        printf("Device count: %d\\n", count);\n    }\n    return 0;\n}\n'})}),"\n",(0,o.jsx)(n.p,{children:"Then, in order to run this script we need to compile it with our CUDA compiler (named: nvcc) and create an executable binary."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"nvcc debug_cuda.cu -o debug_cuda -lcuda\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Now you can run it simply as ",(0,o.jsx)(n.code,{children:"debug_cuda"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"Let's create another script. This time we want to create a simple test that will use our CUDA environment and show the versions used when running the executable code."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-c",children:'#include <cuda.h>\n#include <stdio.h>\n\nint main() {\n    CUresult result = cuInit(0);\n    printf("cuInit: %d\\n", result);\n\n    int count = 0;\n    result = cuDeviceGetCount(&count);\n    printf("cuDeviceGetCount: %d, count: %d\\n", result, count);\n\n    return 0;\n}\n'})}),"\n",(0,o.jsx)(n.p,{children:"It uses the driver API directly and show how many CUDA devices there are (GPUs). Compile and run it:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"nvcc test_cuda.cu -o test_cuda -L/usr/lib64 -lcuda\n./test_cuda\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Another way to test if your workload can access the CUDA devices is using Python3 Torch library. You can install the library using ",(0,o.jsx)(n.code,{children:"pip3"})," and then run a simple python oneliner to check version and count of CUDA devices."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"pip3 install torch\npython3 -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'Device count: {torch.cuda.device_count()}')\"\n"})}),"\n",(0,o.jsx)(n.h2,{id:"possible-solutions",children:"Possible solutions"}),"\n",(0,o.jsx)(n.p,{children:"Hopefully, those scripts will help you understand what is the problem. Some possible scenarios are:"}),"\n",(0,o.jsx)(n.h3,{id:"cuda-driver-and-nvcc-compiler-versions-mismatch",children:"CUDA driver and NVCC (compiler) versions mismatch"}),"\n",(0,o.jsx)(n.p,{children:"One of the most common issues is to use different versions for both of those components. The recommended approach is to have both at the same version."}),"\n",(0,o.jsx)(n.p,{children:"Links you can try to use to debug:"}),"\n",(0,o.jsx)(n.h3,{id:"cuda-device-not-intialized",children:"CUDA device not intialized"}),"\n",(0,o.jsx)(n.p,{children:"Your device needs to be initialized (awakened) to work with your drivers. There are several ways of doing that, including rebooting the server."}),"\n",(0,o.jsx)(n.p,{children:"Links you can try to use to debug:"}),"\n",(0,o.jsx)(n.h3,{id:"nvlink-status-and-topology",children:"NVLink status and topology"}),"\n",(0,o.jsx)(n.p,{children:"It is important to check the status and topology of NVLinks. Those are hardware dependant and can be checked with the following commands:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"nvidia-smi nvlink --status\nnvidia-smi topo -m\nnvidia-smi nvlink --capabilities\n"})}),"\n",(0,o.jsx)(n.p,{children:"The output should give you plenty of information on the hardware topology and specification. This information is useful to understand how to better define paralellism in your jobs and understand the theoretical limits of your hardware solution."})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>a});var t=i(6540);const o={},r=t.createContext(o);function s(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);