"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1615],{1493:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/nvidia-smi-4a0ae3baef20b60f0b5a85be9b2642e4.png"},2674:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"slurm-blueprints/training/megatron-lm/megatron-lm-readme","title":"NVIDIA Megatron-LM","description":"MegatronLM is a framework from Nvidia that can be used to train LLMs. We recommend that you read papers on the framework to know the different knobs you can tune and in particular these articles:","source":"@site/docs/02-slurm-blueprints/training/megatron-lm/megatron-lm-readme.md","sourceDirName":"02-slurm-blueprints/training/megatron-lm","slug":"/slurm-blueprints/training/megatron-lm/megatron-lm-readme","permalink":"/docs/slurm-blueprints/training/megatron-lm/megatron-lm-readme","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"tile":"NVIDIA Megratron-LM","sidebar_position":1,"sidebar_title":"NVIDIA Megatron-LM"},"sidebar":"tutorialSidebar","previous":{"title":"Fully Sharded Data Parallel","permalink":"/docs/slurm-blueprints/training/fsdp/fully-sharded-data-parallel"},"next":{"title":"aws-trainium","permalink":"/docs/slurm-blueprints/training/trainium/aws-trainium"}}');var t=s(4848),r=s(8453);const a={tile:"NVIDIA Megratron-LM",sidebar_position:1,sidebar_title:"NVIDIA Megatron-LM"},o="NVIDIA Megatron-LM",l={},c=[{value:"Preparation",id:"preparation",level:2},{value:"Data Preprocessing",id:"data-preprocessing",level:2},{value:"Steps",id:"steps",level:3},{value:"Training",id:"training",level:2},{value:"Steps",id:"steps-1",level:3},{value:"Monitoring",id:"monitoring",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"nvidia-megatron-lm",children:"NVIDIA Megatron-LM"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/NVIDIA/Megatron-LM",children:"MegatronLM"})," is a framework from Nvidia that can be used to train LLMs. We recommend that you read papers on the framework to know the different knobs you can tune and in particular these articles:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/1909.08053",children:"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/1909.08053",children:"Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"To run a test case you will go through a series of steps described below:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Build the data preprocessing container."}),"\n",(0,t.jsx)(n.li,{children:"Pre-process the data using a tokenizer and the preprocessing container."}),"\n",(0,t.jsx)(n.li,{children:"Build the container for distributed training"}),"\n",(0,t.jsx)(n.li,{children:"Train!"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"We describe the steps below for Slurm users running on a Nvidia GPU."}),"\n",(0,t.jsx)(n.h2,{id:"preparation",children:"Preparation"}),"\n",(0,t.jsxs)(n.p,{children:["This guide assumes that you've ",(0,t.jsx)(n.a,{href:"/docs/getting-started/orchestrated-by-slurm/initial-cluster-setup",children:"built a SageMaker HyperPod Slurm cluster"})," with GPU instances i.e. g5/p4d/p5 instance types. Please make sure you have the following before getting started:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["A Slurm cluster on AWS using Nvidia GPU's i.e. ",(0,t.jsx)(n.code,{children:"g5"}),", ",(0,t.jsx)(n.code,{children:"p4d"})," or ",(0,t.jsx)(n.code,{children:"p5"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Docker, ",(0,t.jsx)(n.a,{href:"https://github.com/NVIDIA/pyxis",children:"Pyxis"})," and ",(0,t.jsx)(n.a,{href:"https://github.com/NVIDIA/enroot",children:"Enroot"})," installed. This is installed by default in the ",(0,t.jsx)(n.a,{href:"https://github.com/aws-samples/awsome-distributed-training/tree/main/1.architectures/5.sagemaker-hyperpod/LifecycleScripts/base-config/utils",children:"lifecycle scripts"})]}),"\n",(0,t.jsxs)(n.li,{children:["An FSx for Lustre filesystem mounted on ",(0,t.jsx)(n.code,{children:"/fsx"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["If you completed ",(0,t.jsx)(n.a,{href:"/docs/getting-started/orchestrated-by-slurm/initial-cluster-setup",children:"Cluster Setup"})," using a Nvidia GPU config these steps are complete."]}),"\n",(0,t.jsx)(n.h2,{id:"data-preprocessing",children:"Data Preprocessing"}),"\n",(0,t.jsxs)(n.p,{children:["Before running training jobs you need to retrieve input data and pre-process it. This section of the guide you will retrieve a container then you convert it into a squash file via ",(0,t.jsx)(n.a,{href:"https://github.com/NVIDIA/enroot",children:"Enroot"}),", you will then retrieve input data and tokenize it using the GPT2 vocabulary."]}),"\n",(0,t.jsx)(n.h3,{id:"steps",children:"Steps"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["First SSH into one of the compute nodes. ",(0,t.jsx)(n.strong,{children:"Note:"})," you can build containers on the head node but you're limited to only 100GB of storage so we recommend building them on a compute node."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# ssh into a compute node\nsalloc -N 1\nssh $(srun hostname)\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"All next steps will be executed on the compute node."}),"\n",(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Next we'll clone the ",(0,t.jsx)(n.a,{href:"https://github.com/aws-samples/awsome-distributed-training/tree/main",children:"Github repo"})," and cd into the right directory:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~\ngit clone https://github.com/aws-samples/awsome-distributed-training.git\ncd awsome-distributed-training/3.test_cases/megatron/megatron-lm\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Next we'll set an environment variable to point to our shared ",(0,t.jsx)(n.code,{children:"/fsx/ubuntu"})," filesystem. This is used in the submission scripts later."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"export DATA_PATH=/fsx/ubuntu # FSx for Lustre shared file-system\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Build the container image with the command below"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"DOCKER_BUILDKIT=1 docker build -t megatron-training -f aws-megatron-lm.Dockerfile .\n"})}),"\n",(0,t.jsxs)(n.admonition,{title:"Important",type:"info",children:[(0,t.jsxs)(n.p,{children:["If you see the following error ",(0,t.jsx)(n.code,{children:"ERROR: permission denied while trying to connect to the Docker daemon socket at..."})," when trying to run ",(0,t.jsx)(n.code,{children:"docker"}),", you'll need to add the user to the ",(0,t.jsx)(n.code,{children:"docker"})," group by running:"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo usermod -aG docker ${USER}\n"})}),(0,t.jsxs)(n.p,{children:["Then log out with ",(0,t.jsx)(n.code,{children:"exit"})," and log back in."]})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Once the image is built, you can check if it is present with ",(0,t.jsx)(n.code,{children:"docker images"}),". You should see an output similar to this one:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[ubuntu@ip-10-0-10-78 ~]$ docker images\nREPOSITORY            TAG       IMAGE ID       CREATED         SIZE\nmegatron-training   latest    de38623b2f85   2 minutes ago   20.7GB\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Create the squash file with the command below."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo enroot import -o megatron-training.sqsh  dockerd://megatron-training:latest\n"})}),"\n",(0,t.jsx)(n.p,{children:"The file will be stored in the current directory (if left as default). The output should look as below."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"[ec2-user@ip-10-0-10-78 ~]$ enroot import -o megatron-training.sqsh  dockerd://megatron-training:latest\n[INFO] Fetching image\n\ne19aa13505c1710876982dc440226dc479da5177dc4770452cc79bedc8b5b41d\n\n[INFO] Extracting image content...\n[INFO] Creating squashfs filesystem...\n\nParallel mksquashfs: Using 32 processors\nCreating 4.0 filesystem on /fsx/.../megatron-training.sqsh, block size 131072.\n[==========================================================/] 299550/299550 100%\n\nExportable Squashfs 4.0 filesystem, gzip compressed, data block size 131072\n   uncompressed data, uncompressed metadata, uncompressed fragments, uncompressed xattrs\n   duplicates are not removed\n...\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Create a script with the code below to retrieve the input datasets and vocabulary. Let's call it retrieve_vocab.sh."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cat <<EOF> retrieve_vocab.sh\n#!/bin/bash\nmkdir -p gpt2\ncd gpt2\n\nwget https://huggingface.co/bigscience/misc-test-data/resolve/main/stas/oscar-1GB.jsonl.xz\nwget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json\nwget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt\nxz -d oscar-1GB.jsonl.xz\n\ncd ..\nEOF\n"})}),"\n",(0,t.jsx)(n.p,{children:"Run chmod to make the script executable, then execute it. Remember this has to be executed within the directory that holds the data processing and training code."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"chmod a+x retrieve_vocab.sh\n./retrieve_vocab.sh  \n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Now submit the file ",(0,t.jsx)(n.code,{children:"1.data-preprocessing.sbatch"})," using the command below:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sbatch slurm/gpt3/1.data-preprocessing.sbatch\n"})}),"\n",(0,t.jsxs)(n.admonition,{title:"Important",type:"caution",children:[(0,t.jsxs)(n.p,{children:["If you see an error ",(0,t.jsx)(n.code,{children:"[ERROR] Command not found: nvidia-container-cli, see https://github.com/NVIDIA/libnvidia-container"}),", you need to install ",(0,t.jsx)(n.code,{children:"nvidia-container-cli"}),". To do that run the following on each compute node:"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\nsed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\nsudo apt-get install -y nvidia-container-toolkit\n"})})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["You will see a new file in your current working directory called ",(0,t.jsx)(n.code,{children:"slurm-XY.out"})," where ",(0,t.jsx)(n.code,{children:"XY"})," is a number. This is your output file and will capture the ",(0,t.jsx)(n.code,{children:"STDOUT"})," and ",(0,t.jsx)(n.code,{children:"STDERR"})," from your job. You can check how it progresses via the command ",(0,t.jsx)(n.code,{children:"tail -f slurm-XY.out"})," but with the relevant filename. The file content will be similar to the below:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"0: Opening /fsx/ubuntu/oscar-1GB.jsonl\n0: Time to startup: 0.9956498146057129\n0: Processed 1000 documents (101.28050670002645 docs/s, 1.258563987556778 MB/s).\n0: Processed 2000 documents (188.07992853480727 docs/s, 2.3571624257619614 MB/s).\n...\n0: Processed 78000 documents (1293.9967304914383 docs/s, 16.67556064420713 MB/s).\n0: Processed 79000 documents (1298.6715286585202 docs/s, 16.763634765830606 MB/s).\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"When you confirmed successful run of the preprocessing job, you can go back to the head node."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"exit\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Voil\xe0! You have executed the preprocessing job. You will go through the steps to run your training job."}),"\n",(0,t.jsx)(n.h2,{id:"training",children:"Training"}),"\n",(0,t.jsx)(n.p,{children:"Now that the data is preprocessed, we will pre-train a GPT-3 model Megatron-LM."}),"\n",(0,t.jsx)(n.h3,{id:"steps-1",children:"Steps"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["First let's adjust the number of GPU's requested to fit the size of our cluster. Edit the file ",(0,t.jsx)(n.code,{children:"2.distributed-training.sbatch"})," and adjust the line ",(0,t.jsx)(n.code,{children:"#SBATCH --nodes=24"})," to the number of instances in your cluster. For example if I had ",(0,t.jsx)(n.code,{children:"8 x p5.48xlarge"})," instances, I would put:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"#!/bin/bash\n\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n\n#SBATCH --nodes=8 # number of nodes to use, 8 p4d(e) = 64 A100 GPUs\n#SBATCH --job-name=megatron_gpt # name of your job\n#SBATCH --exclusive # job has exclusive use of the resource, no sharing\n#SBATCH --wait-all-nodes=1\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Next submit a training job:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sbatch 2.distributed-training.sbatch\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"The training starts running and should produce an output similar to below if successful."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"1:  iteration       25/73242187 | consumed samples:           50 | elapsed time per iteration (ms): 87.0 | learning rate: 1.638E-08 | global batch size:     2 | lm loss: 1.086954E+01 | loss scale: 4294967296.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |\n1:  iteration       26/73242187 | consumed samples:           52 | elapsed time per iteration (ms): 86.5 | learning rate: 1.704E-08 | global batch size:     2 | lm loss: 1.086217E+01 | loss scale: 4294967296.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |\n1:  iteration       27/73242187 | consumed samples:           54 | elapsed time per iteration (ms): 88.4 | learning rate: 1.769E-08 | global batch size:     2 | lm loss: 1.087129E+01 | loss scale: 4294967296.0 | grad norm: 0.000 | number of skipped iterations:   0 | number of nan iterations:   0 |\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"monitoring",children:"Monitoring"}),"\n",(0,t.jsx)(n.p,{children:"Now that the job is running, we can monitor it in two ways, we can tail the log file to see how the training is progressing:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Control-C to stop tailing\ntail -f slurm-2.log\n"})}),"\n",(0,t.jsx)(n.p,{children:"We can also ensure it's utilizing the GPU's appropriately by SSH-ing into the compute node."}),"\n",(0,t.jsxs)(n.p,{children:["Grab the hostname by running ",(0,t.jsx)(n.code,{children:"sinfo"})," and seeing which node it's running on:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sinfo\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\ndev*         up   infinite      1  alloc ip-10-1-90-87\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Then ssh into that instance using the hostname from ",(0,t.jsx)(n.code,{children:"sinfo"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"ssh ip-10-1-90-87\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Once there we can monitor the accelerator usage by running ",(0,t.jsx)(n.code,{children:"nvidia-smi"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"nvidia-smi\n"})}),"\n",(0,t.jsx)(n.p,{children:"You'll see very little usage of the GPU's for the first few minutes as it sets up the case, then you'll see constant usage after that:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Nvidia-smi",src:s(1493).A+"",width:"1618",height:"1340"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>o});var i=s(6540);const t={},r=i.createContext(t);function a(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);