"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3310],{2404:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>u,contentTitle:()=>a,default:()=>c,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"eks-blueprints/fine-tuning/peft/quantisized-lora","title":"QLoRA (Quantized LoRA)","description":"This section is under development. QLoRA fine-tuning documentation will be available soon.","source":"@site/docs/01-eks-blueprints/fine-tuning/peft/quantisized-lora.md","sourceDirName":"01-eks-blueprints/fine-tuning/peft","slug":"/eks-blueprints/fine-tuning/peft/quantisized-lora","permalink":"/docs/eks-blueprints/fine-tuning/peft/quantisized-lora","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"QLoRA (Quantized LoRA)","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"LoRA - Trainium","permalink":"/docs/eks-blueprints/fine-tuning/peft/low-rank-adaptation"},"next":{"title":"dpo","permalink":"/docs/eks-blueprints/fine-tuning/preference-alignment/dpo"}}');var o=t(4848),s=t(8453);const r={title:"QLoRA (Quantized LoRA)",sidebar_position:2},a="QLoRA (Quantized LoRA) Fine-tuning",u={},d=[];function l(e){const n={admonition:"admonition",h1:"h1",header:"header",p:"p",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"qlora-quantized-lora-fine-tuning",children:"QLoRA (Quantized LoRA) Fine-tuning"})}),"\n",(0,o.jsx)(n.admonition,{title:"Coming Soon",type:"note",children:(0,o.jsx)(n.p,{children:"This section is under development. QLoRA fine-tuning documentation will be available soon."})}),"\n",(0,o.jsx)(n.p,{children:"QLoRA (Quantized Low-Rank Adaptation) is an efficient fine-tuning technique that combines quantization with LoRA to reduce memory requirements while maintaining model performance."})]})}function c(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>a});var i=t(6540);const o={},s=i.createContext(o);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);