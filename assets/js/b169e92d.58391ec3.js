"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3255],{7431:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"validation-and-testing/environment-validation/pytorch-environment-validation","title":"PyTorch Environment Validation","description":"This validation script runs a comprehensive PyTorch environment check to screen for NCCL, MPI, OpenMP, CUDA, and other critical components on your HyperPod cluster. The script executes once per instance and helps verify that your environment is properly configured for distributed training.","source":"@site/docs/06-validation-and-testing/environment-validation/pytorch-environment-validation.md","sourceDirName":"06-validation-and-testing/environment-validation","slug":"/validation-and-testing/environment-validation/pytorch-environment-validation","permalink":"/ai-on-sagemaker-hyperpod/docs/validation-and-testing/environment-validation/pytorch-environment-validation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"PyTorch Environment Validation","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Environment Validation","permalink":"/ai-on-sagemaker-hyperpod/docs/category/environment-validation"},"next":{"title":"EFA and Network Stack Validation","permalink":"/ai-on-sagemaker-hyperpod/docs/validation-and-testing/environment-validation/efa-validation"}}');var r=i(4848),s=i(8453);const a={title:"PyTorch Environment Validation",sidebar_position:1},o="PyTorch Environment Validation",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"For Slurm Clusters",id:"for-slurm-clusters",level:3},{value:"For EKS Clusters",id:"for-eks-clusters",level:3},{value:"Slurm Implementation",id:"slurm-implementation",level:2},{value:"1. Get the Validation Scripts",id:"1-get-the-validation-scripts",level:3},{value:"Script Features",id:"script-features",level:3},{value:"1. Build the Validation Container",id:"1-build-the-validation-container",level:3},{value:"3. Use the Provided Slurm Job Script",id:"3-use-the-provided-slurm-job-script",level:3},{value:"4. Run the Validation",id:"4-run-the-validation",level:3},{value:"EKS Implementation",id:"eks-implementation",level:2},{value:"1. Create Kubernetes Job Manifest",id:"1-create-kubernetes-job-manifest",level:3},{value:"2. Monitor and View Results",id:"2-monitor-and-view-results",level:3},{value:"Expected Output",id:"expected-output",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"Validation Checklist",id:"validation-checklist",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"pytorch-environment-validation",children:"PyTorch Environment Validation"})}),"\n",(0,r.jsx)(n.p,{children:"This validation script runs a comprehensive PyTorch environment check to screen for NCCL, MPI, OpenMP, CUDA, and other critical components on your HyperPod cluster. The script executes once per instance and helps verify that your environment is properly configured for distributed training."}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"The PyTorch environment validation performs the following checks:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"CUDA availability and configuration"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"PyTorch backend status"})," (CUDA, cuDNN, MKL, OpenMP)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Distributed training capabilities"})," (NCCL, MPI)"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"GPU driver and library versions"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Container runtime validation"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(n.h3,{id:"for-slurm-clusters",children:"For Slurm Clusters"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Functional Slurm cluster on AWS"}),"\n",(0,r.jsxs)(n.li,{children:["Docker, ",(0,r.jsx)(n.a,{href:"https://github.com/NVIDIA/pyxis",children:"Pyxis"})," and ",(0,r.jsx)(n.a,{href:"https://github.com/NVIDIA/enroot",children:"Enroot"})," installed"]}),"\n",(0,r.jsxs)(n.li,{children:["Shared directory mounted (typically ",(0,r.jsx)(n.code,{children:"/fsx"})," or ",(0,r.jsx)(n.code,{children:"/apps"}),")"]}),"\n",(0,r.jsx)(n.li,{children:"AWS Deep Learning Container access"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"for-eks-clusters",children:"For EKS Clusters"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Functional EKS cluster with GPU nodes"}),"\n",(0,r.jsx)(n.li,{children:"NVIDIA device plugin deployed"}),"\n",(0,r.jsx)(n.li,{children:"Container registry access (ECR or public registries)"}),"\n",(0,r.jsx)(n.li,{children:"kubectl configured for cluster access"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"slurm-implementation",children:"Slurm Implementation"}),"\n",(0,r.jsx)(n.h3,{id:"1-get-the-validation-scripts",children:"1. Get the Validation Scripts"}),"\n",(0,r.jsxs)(n.p,{children:["The PyTorch validation scripts are available in the ",(0,r.jsx)(n.a,{href:"https://github.com/aws-samples/awsome-distributed-training/tree/main/4.validation_and_observability/1.pytorch-env-validation",children:"awsome-distributed-training repository"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Clone the repository\ngit clone https://github.com/aws-samples/awsome-distributed-training.git\ncd awsome-distributed-training/4.validation_and_observability/1.pytorch-env-validation\n"})}),"\n",(0,r.jsx)(n.p,{children:"Available files:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://github.com/aws-samples/awsome-distributed-training/blob/main/4.validation_and_observability/1.pytorch-env-validation/pytorch-screen.py",children:"pytorch-screen.py"}),": Main validation script"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://github.com/aws-samples/awsome-distributed-training/blob/main/4.validation_and_observability/1.pytorch-env-validation/1.torch-screen.sbatch",children:"1.torch-screen.sbatch"}),": Slurm job script"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://github.com/aws-samples/awsome-distributed-training/blob/main/4.validation_and_observability/1.pytorch-env-validation/0.pytorch-screen.Dockerfile",children:"0.pytorch-screen.Dockerfile"}),": Container build file"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"script-features",children:"Script Features"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"pytorch-screen.py"})," script provides comprehensive validation of:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"PyTorch version and configuration"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"CUDA availability and device detection"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"cuDNN backend settings"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Distributed training capabilities"})," (NCCL, MPI)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Backend availability"})," (MKL, OpenMP, opt_einsum)"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Environment variable validation"})}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"1-build-the-validation-container",children:"1. Build the Validation Container"}),"\n",(0,r.jsx)(n.p,{children:"Use the provided Dockerfile from the awsome-distributed-training repository:"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Dockerfile"}),": ",(0,r.jsx)(n.a,{href:"https://github.com/aws-samples/awsome-distributed-training/blob/main/4.validation_and_observability/1.pytorch-env-validation/0.pytorch-screen.Dockerfile",children:(0,r.jsx)(n.code,{children:"0.pytorch-screen.Dockerfile"})})]}),"\n",(0,r.jsx)(n.p,{children:"Build and convert to Enroot format:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Get the region\nAWS_AZ=$(ec2-metadata --availability-zone | cut -d' ' -f2)\nAWS_REGION=${AWS_AZ::-1}\n\n# Authenticate with ECR\naws ecr get-login-password | docker login --username AWS \\\n   --password-stdin 763104351884.dkr.ecr.${AWS_REGION}.amazonaws.com/pytorch-training\n\n# Build the container using the provided Dockerfile\ndocker build -t pytorch-validation -f 0.pytorch-screen.Dockerfile \\\n   --build-arg=\"AWS_REGION=${AWS_REGION}\" .\n\n# Convert to Enroot squash file\nenroot import -o /fsx/pytorch-validation.sqsh dockerd://pytorch-validation:latest\n"})}),"\n",(0,r.jsx)(n.h3,{id:"3-use-the-provided-slurm-job-script",children:"3. Use the Provided Slurm Job Script"}),"\n",(0,r.jsxs)(n.p,{children:["The repository includes a ready-to-use Slurm job script at ",(0,r.jsx)(n.a,{href:"https://github.com/aws-samples/awsome-distributed-training/blob/main/4.validation_and_observability/1.pytorch-env-validation/1.torch-screen.sbatch",children:(0,r.jsx)(n.code,{children:"1.torch-screen.sbatch"})}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Key configuration options in the script:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Node count"}),": Modify ",(0,r.jsx)(n.code,{children:"#SBATCH -N 2"})," to change number of nodes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Container image"}),": Set ",(0,r.jsx)(n.code,{children:"IMAGE"})," variable to your container path"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Shared filesystem"}),": Configure ",(0,r.jsx)(n.code,{children:"FSX_MOUNT"})," for your setup"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"4-run-the-validation",children:"4. Run the Validation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Submit the job\nsbatch pytorch-validation.sbatch\n\n# Monitor the output\ntail -f slurm-<job-id>.out\n"})}),"\n",(0,r.jsx)(n.h2,{id:"eks-implementation",children:"EKS Implementation"}),"\n",(0,r.jsx)(n.h3,{id:"1-create-kubernetes-job-manifest",children:"1. Create Kubernetes Job Manifest"}),"\n",(0,r.jsx)(n.p,{children:"Since there's no pre-built Kubernetes manifest in the awsome-distributed-training repository for PyTorch validation, you can create a simple Job manifest:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Create ConfigMap with the validation script\nkubectl create configmap pytorch-validation-script \\\n  --from-file=pytorch-screen.py\n\n# Create a basic Job manifest\ncat <<EOF | kubectl apply -f -\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pytorch-validation\n  namespace: default\nspec:\n  parallelism: 2\n  completions: 2\n  template:\n    spec:\n      restartPolicy: Never\n      nodeSelector:\n        node.kubernetes.io/instance-type: "p5.48xlarge"\n      containers:\n      - name: pytorch-validation\n        image: <YOUR_BUILT_CONTAINER_IMAGE>\n        command: ["/bin/bash"]\n        args:\n        - -c\n        - |\n          echo "Node: \\$(hostname)"\n          nvidia-smi\n          python /workspace/pytorch-screen.py\n        resources:\n          limits:\n            nvidia.com/gpu: 8\n            vpc.amazonaws.com/efa: 32\n          requests:\n            nvidia.com/gpu: 8\n            vpc.amazonaws.com/efa: 32\n        volumeMounts:\n        - name: validation-script\n          mountPath: /workspace\n      volumes:\n      - name: validation-script\n        configMap:\n          name: pytorch-validation-script\nEOF\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-monitor-and-view-results",children:"2. Monitor and View Results"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Monitor the job\nkubectl get jobs -w\n\n# View logs\nkubectl logs -l job-name=pytorch-validation\n"})}),"\n",(0,r.jsx)(n.h2,{id:"expected-output",children:"Expected Output"}),"\n",(0,r.jsx)(n.p,{children:"The validation script will produce output similar to:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"==================================================\n PyTorch Environment Validation\n==================================================\nPyTorch Version: 2.0.1+cu118\nPython Version: 3.10.11\n\n==================================================\n CUDA Configuration\n==================================================\ntorch.cuda.is_available() = True\ntorch.version.cuda = 11.8\ntorch.backends.cuda.is_built() = True\nCUDA Device Count: 8\n  Device 0: NVIDIA H100 80GB HBM3\n  Device 1: NVIDIA H100 80GB HBM3\n  ...\n\n==================================================\n Distributed Training\n==================================================\ntorch.distributed.is_available() = True\ntorch.distributed.is_mpi_available() = True\ntorch.distributed.is_nccl_available() = True\n\n==================================================\n Validation Complete\n==================================================\nEnvironment validation finished successfully!\n"})}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"CUDA not available"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Verify NVIDIA drivers are installed"}),"\n",(0,r.jsx)(n.li,{children:"Check GPU resource allocation in job spec"}),"\n",(0,r.jsx)(n.li,{children:"Ensure container has GPU access"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"NCCL not available"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Verify NCCL installation in container"}),"\n",(0,r.jsx)(n.li,{children:"Check EFA device plugin deployment (EKS)"}),"\n",(0,r.jsx)(n.li,{children:"Validate network configuration"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Container mount issues (Slurm)"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Verify Enroot/Pyxis installation"}),"\n",(0,r.jsx)(n.li,{children:"Check shared filesystem permissions"}),"\n",(0,r.jsx)(n.li,{children:"Ensure squash file is accessible"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"validation-checklist",children:"Validation Checklist"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u2705 CUDA is available and detects all GPUs"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 NCCL is available for distributed training"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 MPI is available for multi-node communication"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 EFA devices are accessible (if using EFA-enabled instances)"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Container can access shared storage"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Environment variables are properly set"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var t=i(6540);const r={},s=t.createContext(r);function a(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);