"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4024],{6991:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"SLURM Blueprints/Fine Tuning/Preference Alignment/Direct Preference Optimization","title":"Direct Preference Optimization","description":"","source":"@site/docs/2. SLURM Blueprints/Fine Tuning/Preference Alignment/Direct Preference Optimization.md","sourceDirName":"2. SLURM Blueprints/Fine Tuning/Preference Alignment","slug":"/SLURM Blueprints/Fine Tuning/Preference Alignment/Direct Preference Optimization","permalink":"/docs/SLURM Blueprints/Fine Tuning/Preference Alignment/Direct Preference Optimization","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Quantisized LoRA","permalink":"/docs/SLURM Blueprints/Fine Tuning/PEFT/Quantisized LoRA/"},"next":{"title":"Proximal Policy Optimization","permalink":"/docs/SLURM Blueprints/Fine Tuning/Preference Alignment/Proximal Policy Optimization"}}');var r=t(4848),o=t(8453);const s={sidebar_position:1},c=void 0,a={},u=[];function l(e){return(0,r.jsx)(r.Fragment,{})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l()}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>c});var i=t(6540);const r={},o=i.createContext(r);function s(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);